# ***Algorithm***
## ***88. Merge Sorted Array***
### Description
Given two sorted integer arrays nums1 and nums2, merge nums2 into nums1 as one sorted array.

Note:

The number of elements initialized in nums1 and nums2 are m and n respectively.
You may assume that nums1 has enough space (size that is greater or equal to m + n) to hold additional elements from nums2.
### Example:

Input:
nums1 = [1,2,3,0,0,0], m = 3
nums2 = [2,5,6],       n = 3

Output: [1,2,2,3,5,6]
### My Solution In Java
```
class Solution {
    public void merge(int[] nums1, int m, int[] nums2, int n) {
       int count = m + n - 1;
        m = m - 1;
        n = n - 1;
        while (m >= 0 && n >= 0) {
            nums1[count--] = nums1[m] > nums2[n] ? nums1[m--] : nums2[n--];}
        while (n >= 0) {
            nums1[count--] = nums2[n--];
        }
    }
}
```
### Analyse
My first solution is quite ugly which I don't want to share in here.Then I read the some brief solution on a blog.Here is the thought,the merged array's length is m+n,we can merging  the array  from the largest index(m+n-1) to m or n(depends on the sort).It will be done in the first merging round if  all the elements in nums2 are bigger than which nums1,otherwise we can merging the rest in nums2 in the secoud round.
# ***Review***
### ***Original Artical:https://medium.com/@magnus.chatt/why-you-should-totally-switch-to-kotlin-c7bbde9e10d5***
### ***My Review***
```
The author suggest that java developer use Kotlin in the next project,
because he think It’s pragmatic and concise, and makes coding a satisfying and efficient experience.
And it has the following feathers compare to java:
0# ***Java Interoperability*** Kotlin is 100% interoperable with Java，all your favorite Java frameworks are still available.
1# ***Familiar Syntax***  Its syntax is familiar to any programmer coming from the OOP domain.
2# ***String Interpolation***  A smarter and more readable version of Java’s String.format().
3# ***Type Inference***   Kotlin will infer your types。
4# ***Smart Casts***    The Kotlin compiler tracks your logic and auto-casts types if possible.
5# ***Intuitive Equals*** You can stop calling equals() ,replacing it with "==".
6# ***Default Arguments*** 
7# ***Named Arguments***
8# ***The When Expression*** The switch case is replaced with the much more readable and flexible when expression.
9# ***Properties***  Custom set & get behavior can be added to public fields.
10# ***The Data Class***    Unlike in Java it won’t take up 100 lines of code.
11# ***Operator Overloading***   A predefined set of operators can be overloaded to improve readability.
12# ***Destructuring Declarations***  Some objects can be destructured, which is for example useful for iterating maps.
13# ***Ranges***  
14# ***Extension Functions***    In Kotlin,there was a way to add new functions to old classes,such as List and String rather than Util Classes in Java.
15# ***Null Safety*** Java developers have to live in constant fear of NPEs.Kotlin resolves this by distinguishing between non-null types and nullable types.
16# ***Better Lambdas***
17# ***IDE Support***

Summary,in my exeprience,kotlin is similar to another JVM language--scala.
Both languages are more concise,but kotlin is easier to read and write than scala.
So I will try to use it in my next project.

```

# ***Tip***
上周在做ElasticSearch基于snapshot api备份到hdfs上，下面是一些具体用法和建议。

1、es集群数据备份

任何一个存储数据的软件，都需要定期的备份我们的数据。es replica提供了运行时的高可用保障机制，可以容忍少数节点的故障和部分数据的丢失，但是整体上却不会丢失任何数据，而且不会影响集群运行。但是replica没法进行灾难性的数据保护，比如说机房彻底停电，所有机器全部当即，等等情况。对于这种灾难性的故障，我们就需要对集群中的数据进行备份了，集群中数据的完整备份。

要备份集群数据，就要使用snapshot api。这个api会将集群当前的状态和数据全部存储到一个外部的共享目录中去，比如NAS，或者hdfs。而且备份过程是非常智能的，第一次会备份全量的数据，但是接下来的snapshot就是备份两次snapshot之间的增量数据了。数据是增量进入es集群或者从es中删除的，那么每次做snapshot备份的时候，也会自动在snapshot备份中增量增加数据或者删除部分数据。因此这就意味着每次增量备份的速度都是非常快的。

如果要使用这个功能，我们需要有一个预先准备好的独立于es之外的共享目录，用来保存我们的snapshot备份数据。es支持多种不同的目录类型：基于hdfs创建仓库，比如NAS；Amazon S3；hdfs；Azure Cloud。不过对于国内的情况而言，其实NAS应该很少用，一般来说，就用hdfs会比较多一些，跟hadoop这种离线大数据技术栈整合起来使用。

2、创建备份仓库

（1）基于shared filesystem创建仓库
```
PUT _snapshot/my_backup 
{
    "type": "fs", 
    "settings": {
        "location": "/mount/backups/my_backup" 
    }
}
```
这里用了shared filesystem作为仓库类型，包括了仓库名称以及仓库类型是fs，还有仓库的地址。这个里面就包含了仓库的一些必要的元数据了。可能还有其他的一些参数可以配置，主要是基于我们的node和网络的性能来配置。max_snapshot_bytes_per_sec，这个参数用于指定数据从es灌入仓库的时候，进行限流，默认是20mb/s。max_restore_bytes_per_sec，这个参数用于指定数据从仓库中恢复到es的时候，进行限流，默认也是20mb/s。假如说网络是非常快速的，那么可以提高这两个参数的值，可以加快每次备份和恢复的速度，比如下面：
创建一个仓库之后，就可以查看这个仓库的信息了：GET /_snapshot/my_backup，或者是查看所有的仓库，GET /_snapshot/_all。

(2)基于hdfs创建仓库

建议不采用基于shared filesystem创建仓库，公司有hadoop环境的话最好是用hadoop生态的hdfs分布式文件存储系统。
首先先要安装repository-hdfs的插件：bin/elasticsearch-plugin install repository-hdfs，必须在每个节点上都安装，然后重启整个集群。
在hdfs node上，都hdfs-site.xml，禁止权限检查
```
<property>
  <name>dfs.permissions</name>
  <value>false</value>
</property>
```
hdfs snapshot/restore plugin是跟最新的hadoop 2.x整合起来使用的，目前是hadoop 2.7.1。所以如果我们使用的hadoop版本跟这个es hdfs plugin的版本不兼容，那么考虑在hdfs plugin的文件夹里，将hadoop相关jar包都替换成我们自己的hadoop版本对应的jar包。即使hadoop已经在es所在机器上也安装了，但是为了安全考虑，还是应该将hadoop jar包放在hdfs plugin的目录中。

安装好了hdfs plugin之后，就可以创建hdfs仓库了，用如下的命令即可：
```
curl -XPUT 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository' -d '
{
  "type": "hdfs",
  "settings": {
    "uri": "hdfs://elasticsearch02:9000/",
    "path": "elasticsearch/respositories/my_hdfs_repository",
	"conf.dfs.client.read.shortcircuit": "false",
	"max_snapshot_bytes_per_sec" : "50mb", 
    "max_restore_bytes_per_sec" : "50mb"
  }
}'
```
（3）验证仓库

如果一个仓库被创建好之后，我们可以立即去验证一下这个仓库是否可以在所有节点上正常使用。verify参数都可以用来做这个事情，比如下面的命令。这个命令会返回一个node列表，证明那些node都验证过了这个仓库是ok的，可以使用的
```
curl -XPOST 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository/_verify'
```
3、对索引进行snapshotting备份

（1）对所有open的索引进行snapshotting备份

一个仓库可以包含多分snapshot，每个snapshot是一部分索引的备份数据，创建一份snapshot备份时，我们要指定要备份的索引。比如下面这行命令：PUT _snapshot/my_hdfs_repository/snapshot_1，这行命令就会将所有open的索引都放入一个叫做snapshot_1的备份，并且放入my_backup仓库中。这个命令会立即返回，然后备份操作会被后台继续进行。如果我们不希望备份操作以后台方式运行，而是希望在前台发送请求时等待备份操作执行完成，那么可以加一个参数即可，比如下面这样：PUT _snapshot/my_backup/snapshot_1?wait_for_completion=true。
```
curl -XPUT 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository/snapshot_1'
```
（2）对指定的索引进行snapshotting备份

默认的备份是会备份所有的索引，但是有的时候，可能我们不希望备份所有的索引，有些可能是不重要的数据，而且量很大，没有必要占用我们的hdfs磁盘资源，那么可以指定备份少数重要的数据即可。此时可以使用下面的命令去备份指定的索引：
```
PUT _snapshot/my_backup/snapshot_2
{
    "indices": "index_1,index_2",
	"ignore_unavailable": true,
	"include_global_state": false,
	"partial": true
}
```
ignore_unavailable如果设置为true的话，那么那些不存在的index就会被忽略掉，不会进行备份过程中。默认情况下，这个参数是不设置的，那么此时如果某个index丢失了，会导致备份过程失败。设置include_global_state为false，可以阻止cluster的全局state也作为snapshot的一部分被备份。默认情况下，如果某个索引的部分primary shard不可用，那么会导致备份过程失败，那么此时可以将partial设置为true。

而且snapshotting的过程是增量进行的，每次执行snapshotting的时候，es会分析已经存在于仓库中的snapshot对应的index file，然后仅仅备份那些自从上次snapshot之后新创建的或者有过修改的index files。这就允许多个snapshot在仓库中可以用一种紧凑的模式来存储。而且snapshotting过程是不会阻塞所有的es读写操作的，然而，在snapshotting开始之后，写入index中的数据，是不会反应到这次snapshot中的。每次snapshot除了创建一份index的副本之外，还可以保存全局的cluster元数据，里面包含了全局的cluster设置和template。

每次只能执行一次snapshot操作，如果某个shard正在被snapshot备份，那么这个shard此时就不能被移动到其他node上去，这会影响shard rebalance的操作。只有在snapshot结束之后，这个shard才能够被移动到其他的node上去。

4、查看snapshot备份列表

一旦我们在仓库中备份了一些snapshot之后，就可以查看这些snapshot相关的详细信息了，使用这行命令就可以查看指定的snapshot的详细信息：GET _snapshot/my_backup/snapshot_2，结果大致如下所示。当然也可以查看所有的snapshot列表，GET _snapshot/my_backup/_all。
```
curl -XGET 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository/snapshot_1?pretty'
```
5、删除snapshot备份

如果要删除过于陈旧的snapshot备份快照，那么使用下面这行命令即可：DELETE _snapshot/my_backup/snapshot_2。记住，一定要用api去删除snapshot，不要自己手动跑到hdfs里删除这个数据。因为snapshot是增量的，有可能很多snapshot依赖于底层的某一个公共的旧的snapshot segment。但是delete api是理解数据如何增量存储和互相依赖的，所以可以正确的删除那些不用的数据。如果我们自己手工进行hdfs文件删除，可能导致我们的backup数据破损掉，就无法使用了。
```
curl -XDELETE 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository/snapshot_1'
```
6、监控snapshotting的进度

使用wait_for_completion可以在前台等待备份完成，但是实际上也没什么必要，因为可能要备份的数据量特别大，所以一般还是在后台运行备份过程，然后使用另外一个监控api来查看备份的进度，首先可以获取一个snapshot ID：GET _snapshot/my_backup/snapshot_3。如果这个snapshot还在备份过程中，此时我们就可以看到一些信息，比如什么时候开始备份的，已经运行了多长时间，等等。然而，这个api用了跟snapshot一样的线程池去执行，如果我们在备份非常大的shard，进度的更新可能会非常之慢。一个更好的选择是用_status API，GET _snapshot/my_backup/snapshot_3/_status，这个api立即返回最详细的数据。这里我们可以看到总共有几个shard在备份，已经完成了几个，还剩下几个，包括每个索引的shard的备份进度：
```
curl -XGET 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository/snapshot_1'
```
7、取消snapshotting备份过程

如果我们想要取消一个正在执行的snapshotting备份过程，比如我们发现备份时间过于长，希望先取消然后在晚上再运行，或者是因为不小心误操作发起了一次备份操作，这个时候就可以运行下面这条命令：DELETE _snapshot/my_backup/snapshot_3。也就是立即删除这个snapshot，这个命令会去取消snapshot的过程，同时将备份了一半的仓库中的数据给删除掉。
```
curl -XDELETE 'http://elasticsearch02:9200/_snapshot/my_hdfs_repository/snapshot_1'
```
# ***Share***

本周我在阅读耗叔在《程序员练级攻略（2018）：分布式架构经典图书和论文》中推荐的英文书籍<Designing Data-Intensive Applications>，
在这一周中读的速度比较慢，读完了PART I：Foundations of Data Systems >> Chapter I：Reliable, Scalable, and Maintainable Applications
这部分的内容在纸质书上一共25页，PDF上一共47页，内容比较简单，相大家只要接触过各种各样的数据存储引擎的都很容易理解。主要就是给全书后面的内容做一个铺垫，我简单总结一下,以下是我的读书笔记。
当今世界的很多应用都是数据密集型，CPU的性能很少成为瓶颈，反而是大数据量，数据的复杂性和数据变化的速率会引起很多问题。
一个数据密集型的应用通常是为了提供一些目前比较常用的功能，通过一些比较标准的构建模式构建起来的，比如现在很多应用都需要以下几个特点:
    
• 存储数据，以便后续查找 (数据库)
• 记住一些耗时操作的结果，以便下次可以加快查询 (缓存)
• 允许用户通过关键字进行检索或者各种各样的过滤 (搜索引擎)
• 发送消息给另外的进程异步处理 (流式处理)
• 阶段性的对大数据量进行计算 (批处理)
    
由于不同的应用对数据存储有着不同的需求，所以产生了现代的各种各种的有着不同特性的数据存储系统，各式缓存策略，不同的建索引的方式等等。
在构建应用时我们就要想清楚该采用哪种工具哪种策略最合适，有的时候一种工具无法满足需求时可能还得结合各种工具一起使用。
这本书后面的内容就是围绕各种数据存储系统的优缺点，共同点，有哪些地方导致它们有这些差异的，以及如何实现它们各自的特性的等等这些地方进行讨论。
这一章节主要就是讨论这些各式各样的数据存储系统要实现的最基本的目标：可靠的、可伸缩的和可维护的数据存储系统。我们集中讨论软件系统的最重要的三个关注点：
***Reliability(可靠性)***
系统即使在出现硬件错误、软件错误或者人为错误的情况下也应该持续运行正常，在预期的性能下执行正确的功能。一般来说系统只要达到了以下几点就可以说是可靠的：
• 正确执行了功能，返回预期的结果
• 可以容错（硬件错误、软件错误或者人为错误）
• 满足在预期的负载和数据体量下的的性能要求
• 阻止未授权的访问和滥用

***Scalability（可伸缩性）***
随着系统数据体量、数据传输体量以及数据复杂度的增加，负载也会随之增加，应该有合理的方式来处理这些增长。
### 如何描述负载？
能够用来描述增长的因素叫做负载因子，根据系统架构的不同有着不同的最佳负载因子来描述系统增长，有可能是每秒用户请求数，数据库读写频率，聊天室同时在线人数，缓存命中率等等
用推特的案例来描述：在每个用户登录推特主页时，主页要展示他们关注的人在一段时间的推特信息流，技术团队早期的实现方式是在用户请求个人主页信息流时才去查询这些信息流，很艰难地维持这些查询的负载，特别是对于一些名人有着非常多的follower（千万级别）的情况
后面换成了预先计算的方式（提前把每个用户主页信息流统计好然后存储在每个用户的缓存中，类似于邮件收件箱一样的方式）之后，效果就好了很多，因为用户发推的频率（写）比用户查看推特信息流（读）的频率少两个数量级。因此，每个用户的follower的分布情况是非常重要的一个用于描述负载的因子，对于有着大量粉丝名人的推特情况还得单独处理。
### 如何描述性能？
一旦确定了如何描述系统负载，那么你可以观察当负载因子的值增大后会出现什么情况。可以有两个角度来观察，
当系统资源（CPU，内存，网络带宽等）固定时，增大负载因子的值，系统性能是否有影响？
当增加负载因子的值后，要保持系统性能不受影响，需要增加多少系统资源？
以上两个问题都需要依据性能指标，在hadoop这样的批处理系统中我们一般关心系统吞吐量——每秒处理的记录数，或者特定数据量下一个任务运行的总时间，一般的线上系统我们关心服务的响应时间。一个同样的请求我们反复请求，每次的响应时间都可能不一样，造成不一样的原因有很多，进程/线程上下文切换、网络丢包导致TCP协议重传、垃圾回收处理机制、缺页异常导致从读磁盘、服务器机架共振等等都有可能导致随机的延时。
因此在实际中，由于系统同时在处理各种各样的请求，因此响应时间很可能在某一个范围波动，所以我们不应该只关心响应时间这么一个数字，而是响应时间的范围分布，
时间范围的指标可以由算术平均值来描述，当然有时我们关心系统典型的响应时间，平均值就不是一个很好的度量，它没法反应大多数用户的体验。
最好是通过百分位数来表示，通过百分位数更能直观的了解用户的体验情况，比如50%的点是一个中位数，如果中位数的响应时间是200ms，那么说明一半的请求小于200ms，另一半请求超过200ms。
另外，通过百分位数也能更找到那些异常点（outliers），通过查看高百分位数比如p95, p99, and p999的响应，可以知道系统中有多少请求快过在极限情况下的响应，如果p95是1.5s，那么100个请求中有95个请求是小于1.5s的。
对于这些高百分位数区间的响应时间，一般是由于队列延迟（queueing delays）导致的，一个服务器由于受到CPU核数的限制，只能同时并行处理小部分的工作。当一些慢响应的请求占据了CPU资源，阻挡服务器接受随后的请求时，就出现了所谓的头部队列阻塞（head-of-line blocking）效应，即使这些小请求处理起来很快，也要等待之前的请求处理完成，所以在客户端看起来，这些本来很快处理完成的小请求也变得很慢。
因此在人工压测的时候需要模拟这样的场景，通过调整各种度量来缩短等待队列的长度。
另外一种情况也会导致响应时间慢，当需要某几个后台终端调用来处理一个用户请求时，一个很慢的后台终端请求会拖慢整个请求。
### 如何处理负载增长？
一般来说一个系统架构如果能够支撑某一个级别的负载，那么当系统负载增加十倍之后，这个系统是无法支持的。
在设计可伸缩的架构的时候总会在scaling up（垂直拓展，采用更强大的机器）和scaling out（水平扩展，把负载分摊到很多普通机器上）中权衡，
把负载分摊到很多普通机器上又被称为无共享架构（shared-nothing），运行在单一机器上的系统往往更加简单，但是高端的机器通常很昂贵，
因此负载增大之后很难避免采用水平扩展的方式，，但是将系统拆分到多态机器上面运行又会给系统引入一定的复杂度。
大数据体量功能复杂的应用的架构一般都是高度定制化的，没有所谓的万能架构。
数据读写体量，数据存储体量，数据本身的复杂性，响应时间要求，不同的访问策略都会影响可伸缩的架构设计。

***Maintainability（可持续维护性）***
随着时间推移，有各种各样的人来在系统上做一些操作，系统应该便于维护。
大家都知道软件花费精力最多的地方并不是在最开始的开发阶段，而是上线后的长期运维阶段——修复bug、维持系统运行、定位排查问题、适配新平台、为新的用户案例修改加入新特性等等。
相信大家都不愿意去碰一个由于各种历史遗留原因导致非常难以维护的遗留系统，因此在设计系统时就要考虑到系统的可持续维护性，
为了避免让系统变成非常难以维护的遗留系统，一般来说有一下几个设计原则：
### Operability
让运维团队可以方便地去维护系统，优秀的运维团队应该做到以下几点：
• 让运维团队可以方便地去维护系统，优秀的运维团队应该做到以下几点：
• 监控系统健康状态，到服务状态异常时可以快速恢复服务。
• 定位排查导致异常的原因，比如系统失效或者性能降级问题。
• 保持软件和平台都是最新版本，包括一些安全方面的补丁。
• 要清楚各个系统间的依赖关系，每个系统如何影响另外的系统，提前规避可能导致问题的操作。
• 思考以后可能出现的问题，在问题没有出现之前就解决掉。
• 建立使用工具进行部署和配置管理等的最佳实践。
• 可以进行负载的维护工作，比如迁移应用到另一个平台。
• 在系统配置改变时也能随时保持系统的安全性。
• 建立让运维操作的结果可以被预测的流程，保持生产环境稳定。
• 建立系统维护的知识库，在人员变动的情况下也能正常维护系统。
### Simplicity
应该善用抽象，尽量隐藏/降低系统的复杂度，让工程师便于理解。
### Evolvability(Extensibility, Modifiability, Plasticity)
应该让系统可以很方便的加入新特性。



