# ***Algorithm***
## ***Two Sum***
### Description
Given an array of integers, return indices of the two numbers such that they add up to a specific target.

You may assume that each input would have exactly one solution, and you may not use the same element twice.

### Example:

Given nums = [2, 7, 11, 15], target = 9,

Because nums[0] + nums[1] = 2 + 7 = 9,
return [0, 1].
### My Solution In Java
```
class Solution {
    public int[] twoSum(int[] nums, int target) {
        int[] res = new int[2];
        for(int i=0;i<nums.length;i++){
            for(int j=i+1;j<nums.length;j++){
                if(nums[i]+nums[j] == target){
                    res[0] = i;
                    res[1] = j;
                    return res;
                }
            }
        }
        throw new RuntimeException("no suitable elements for given target!");
    }
}
```
### Analyse
my solution is simple,exactly same idea with [Approach 1: Brute Force] in  the [Solution Tab] given by leecode,just loop through each element xx and find if there is another value that equals to (target-x).
I found that there are more effiective ways to solve this problem by introducing a hash table, the hash table maintains a mapping of each element in the array to its index,which can reduce the look up time from O(n) to O(1) by trading space for speed.Here is the code,which is more effictive than my solution,especialy when the array is large.
```
public int[] twoSum(int[] nums, int target) {
    Map<Integer, Integer> map = new HashMap<>();
    for (int i = 0; i < nums.length; i++) {
        int complement = target - nums[i];
        if (map.containsKey(complement)) {
            return new int[] { map.get(complement), i };
        }
        map.put(nums[i], i);
    }
    throw new IllegalArgumentException("No two sum solution");
}
```
# ***Review***
### ***Original Artical:https://medium.com/@magnus.chatt/why-you-should-totally-switch-to-kotlin-c7bbde9e10d5***
### ***My Review***
```
The author suggest that java developer use Kotlin in the next project,
because he think It’s pragmatic and concise, and makes coding a satisfying and efficient experience.
And it has the following feathers compare to java:
0# ***Java Interoperability*** Kotlin is 100% interoperable with Java，all your favorite Java frameworks are still available.
1# ***Familiar Syntax***  Its syntax is familiar to any programmer coming from the OOP domain.
2# ***String Interpolation***  A smarter and more readable version of Java’s String.format().
3# ***Type Inference***   Kotlin will infer your types。
4# ***Smart Casts***    The Kotlin compiler tracks your logic and auto-casts types if possible.
5# ***Intuitive Equals*** You can stop calling equals() ,replacing it with "==".
6# ***Default Arguments*** 
7# ***Named Arguments***
8# ***The When Expression*** The switch case is replaced with the much more readable and flexible when expression.
9# ***Properties***  Custom set & get behavior can be added to public fields.
10# ***The Data Class***    Unlike in Java it won’t take up 100 lines of code.
11# ***Operator Overloading***   A predefined set of operators can be overloaded to improve readability.
12# ***Destructuring Declarations***  Some objects can be destructured, which is for example useful for iterating maps.
13# ***Ranges***  
14# ***Extension Functions***    In Kotlin,there was a way to add new functions to old classes,such as List and String rather than Util Classes in Java.
15# ***Null Safety*** Java developers have to live in constant fear of NPEs.Kotlin resolves this by distinguishing between non-null types and nullable types.
16# ***Better Lambdas***
17# ***IDE Support***

Summary,in my exeprience,kotlin is similar to another JVM language--scala.
Both languages are more concise,but kotlin is easier to read and write than scala.
So I will try to use it in my next project.
```
# ***Tip***
We developers like to write codes when we want to meet the needs.But sometimes we do not  have to write actual codes.It's helpful when we can meet the needs by using tools.
Last week,I was told to extract some data from two MYSQL databases and combine the two tables from two databases ,and make some transformation finally write the results into the Mongodb.
I can do it by writing codes ,but since I was learning Pentaho Kettle recently,I  want to try to finish the task by using Pentaho Kettle.After solving few problems I finally finished the task with Pentaho Kettle.Here is what I created by Pentaho Kettle Spoon.
![kettle transform](https://raw.githubusercontent.com/Daheyoyo/arts/master/9C7D2703B4D926697C62C55173D43919.png)

The benifits of using tool instead of writing code,is that the needs may change often,it's easy to adjust it in tool rather that changing codes.

# ***Share***
本周的Share是我最近在看的一个大数据OLAP技术。以下是我在看的过程中做的笔记整理的一个文档，其中包含大量截图由于github贴图不太方便暂时就不贴图，对这个笔记感兴趣的同学可以单独找我，我会把文档发出来。以下是文档的文本内容部分。

Apache Kylin是什么
Apache Kylin是一个开源的分布式分析引擎，提供Hadoop/Spark之上的SQL查询接口及多维分析（OLAP）能力以支持超大规模数据，它能在亚秒内查询巨大的Hive表。

Apache Kylin的工作原理
Apache Kylin的工作原理本质上是MOLAP（Multidimensional Online Analytical Processing）Cube，也就是多维立方体分析。这是数据分析中相当经典的理论，下面将对其做简要介绍。

维度和度量
在说明MOLAP Cube之前需要先介绍一下维度（Dimension）和度量（Measure）这两个概念。简单来讲，维度就是观察数据的角度。比如电商的销售数据，可以从时间的维度来观察，也可以进一步细化，从时间和地区的维度来观察。维度一般是一组离散的值，比如时间维度上的每一个独立的日期，或者商品维度上的每一件独立的商品。因此统计时可以把维度值相同的记录聚合在一起，然后应用聚合函数做累加、平均、去重复计数等聚合计算。度量就是被聚合的统计值，也是聚合运算的结果，它一般是连续的值，销售额，抑或是销售商品的总件数。通过比较和测算度量，可以对数据进行评估，比如今年的销售额相比去年有多大的增长，增长的速度是否达到预期，不同商品类别的增长比例是否合理等。

Cube和Cuboid
有了维度和度量，一个数据表或数据模型上的所有字段就可以分类了，它们要么是维度，要么是度量（可以被聚合）。于是就有了根据维度和度量做预计算的Cube理论。给定一个数据模型，我们可以对其上的所有维度进行组合。对于N个维度来说，组合的所有可能性共有2 N 种。对于每一种维度的组合，将度量做聚合运算，然后将运算的结果保存为一个物化视图，称为Cuboid。所有维度组合的Cuboid作为一个整体，被称为Cube。所以简单来说，一个Cube就是许多按维度聚合的物化视图的集合。下面来列举一个具体的例子。假定有一个电商的销售数据集，其中维度包括时间（Time）、商品（Item）、地点（Location）和供应商（Supplier），度量为销售额（GMV）。那么所有维度的组合就有2 4 =16种，比如一维度（1D）的组合有[Time]、[Item]、[Location]、[Supplier]4种；二维度（2D）的组合有[Time，Item]、[Time，Location]、[Time、Supplier]、[Item，Location]、[Item，Supplier]、[Location，Supplier]6种；三维度（3D）的组合也有4种；最后零维度（0D）和四维度（4D）的组合各有1种，总共就有16种组合。
计算Cuboid，即按维度来聚合销售额。如果用SQL语句来表达计算Cuboid[Time，Location]，那么SQL语句如下：
select Time,Location,Sum(GMV) from sales groub by Time,Location
将计算的结果保存为物化视图，所有Cuboid物化视图的总称就是Cube。


Apache Kylin工作原理
Apache Kylin的工作原理就是对数据模型做Cube预计算，并利用计算的结果加速查询，具体工作过程如下。
1）指定数据模型，定义维度和度量。
2）预计算Cube，计算所有Cuboid并保存为物化视图。
3）执行查询时，读取Cuboid，运算，产生查询结果。
 
由于Kylin的查询过程不会扫描原始记录，而是通过预计算预先完成表的关联、聚合等复杂运算，并利用预计算的结果来执行查询，因此相比非预计算的查询技术，其速度一般要快一到两个数量级，并且这点在超大的数据集上优势更明显。当数据集达到千亿乃至万亿级别时，Kylin的速度甚至可以超越其他非预计算技术1000倍以上。

Apache Kylin的技术架构
Apache Kylin系统可以分为在线查询和离线构建两部分，技术架构如下图所示，在线查询的模块主要处于上半区，而离线构建则处于下半区。
 
首先来看看离线构建的部分。从上图可以看出，数据源在左侧，目前主要是Hadoop Hive，保存着待分析的用户数据。根据元数据的定义，下方构建引擎从数据源hive(1.5+版本支持kafka)抽取数据，并构建Cube。数据以关系表的形式输入，符合星形模型（Star Schema）（2.x支持更复杂的雪花模型）。MapReduce是主要的构建技术(2.x支持以spark为构建技术)。构建后的Cube保存在右侧的存储引擎中，一般选用HBase作为存储。完成了离线构建之后，用户可以从上方查询系统发送SQL进行查询分析。Kylin提供了各种Rest API、JDBC/ODBC接口。无论从哪个接口进入，SQL最终都会来到Rest服务层，再转交给查询引擎进行处理。查询引擎解析SQL，生成基于关系表的逻辑执行计划，然后将其转译为基于Cube的物理执行计划，最后查询预计算生成的Cube并产生结果。整个过程不会访问原始数据源（2.x版本也可以配置pushdown讲cube查询不了的sql转发到其他sql引擎）。


Apache Kylin的主要特点
Apache Kylin的主要特点包括支持SQL接口、支持超大数据集、亚秒级响应、可伸缩性、高吞吐率、BI工具集成等。

标准SQL接口
Apache Kylin以标准SQL作为对外服务的主要接口。因为SQL是绝大多数分析人员最熟悉的工具，同时也是大多数应用程序使用的编程接口。 Kylin使用的查询模型是数据源中的关系模型表，一般而言，也就是指Hive表。终端用户只需要像原来查询Hive表一样编写SQL，就可以无缝地切换到Kylin，几乎不需要额外的学习，甚至原本的Hive查询也因为与SQL同源，大多都无须修改就能直接在Kylin上运行。

支持超大数据集
Apache Kylin对大数据的支撑能力可能是目前所有技术中最为领先的。早在2015年eBay的生产环境中Kylin就能支持百亿记录的秒级查询，之后在移动的应用场景下又有了千亿记录秒级查询的案例。这些都是实际场景的应用，而非实验室中的理论数据。因为使用了Cube预计算技术，在理论上，Kylin可以支撑的数据集大小没有上限，仅受限于存储系统和分布式计算系统的承载能力，并且查询速度不会随数据集的增大而减慢。Kylin在数据集规模上的局限性主要在于维度的个数和基数（维度的不同值的总数）。它们一般由数据模型来决定，不会随着数据规模的增长而线性增长，这也意味着Kylin对未来数据的增长有着更强的适
应能力。
对于Apache Kylin，除了eBay将其作为孵化公司有广泛应用之外，国内外一线的互联网公司对此几乎都有大规模的使用，包括百度、网易、京东、美团、唯品会等。此外，其在传统行业中也有非常多的实际应用，包括中国移动、银联、国美等。据不完全统计，真实上线的Apache Kylin用户已经超过了一百多家，在开源后一年多一点的时间内能有如此大的全球用户基础，足见Kylin在处理超大规模数据集上的能力和优势。

亚秒级响应
Apache Kylin拥有优异的查询响应速度，这点得益于预计算，很多复杂的计算，比如连接、聚合，在离线的预计算过程中就已经完成，这大大降低了查询时刻所需要的计算量，提高了响应速度。根据可查询到的公开资料可以得知，Apache Kylin在某生产环境中90%的查询可以在3s内返回结果。这并不是说一小部分SQL相当快，而是在数万种不同SQL的真实生产系统中，绝大部分的查询都非常迅速；在另外一个真实的案例中，对1000多亿条数据构建了立方体，90%的查询性能都在1.18s以内，可见Kylin在超大规模数据集上表现优异。这与一些只在实验室中，只在特定查询情况下采集的性能数据不可同日而语。当然并不是使用Kylin就一定能获得最好的性能。针对特定的数据及查询模式，往往需要做进一步的性能调优、配置优化等，性能调优对于充分利用好Apache Kylin至关重要。

可伸缩性和高吞吐率
 
在保持高速响应的同时，Kylin有着良好的可伸缩性和很高的吞吐率。下图是来自网易的性能分享。下图中左侧是Kylin查询速度与Mondrian/Oracle的对比，可以看到在3个测试查询中，Kylin分别比Mondrian/Oracle快147倍、314倍和59倍。同时，上图中右侧展现了Kylin的吞吐率及其可伸缩性。在只有1个Kylin实例的情况下，Kylin每秒可以处理近70个查询，已经远远高于每秒20个查询的一般水平。更为理想的是，随着服务器的增加，吞吐率也呈线性增加，存在4个实例时可达到每秒230个查询左右，而这4个实例仅部署在一台机器上，理论上添加更多的应用服务器后可以支持更大的并发率。这主要还是归功于预计算降低了查询时所需的计算总量，单次查询所需的计算资源大大减少，令Kylin可以在相同的硬件配置下承载更多的并发查询。


BI及可视化工具集成
Apache Kylin提供了丰富的API，提供ODBC接口，JDBC接口，REST API，可以与现有的BI工具（Tableau、Excel、Power BI以及superset）集成。另外，Kylin核心开发团队也贡献了Apache Zeppelin的插件，现在已经可以用Zeppelin来访问Kylin服务。

与其他开源产品比较
与Apache Kylin一样致力于解决大数据查询问题的其他开源产品也有不少，比如Apache Drill、Apache Impala、Druid、Hive、Presto（Facebook）、SparkSQL、Greenplum等。将Kylin与它们做一个简单的比较。从底层技术的角度来看，这些开源产品有很大的共性，一些底层技术几乎被所有的产品一致采用，Kylin也不例外。

大规模并行处理（Massive Parallel Processing ，MPP）：可以通过增加机器的方式来扩容处理速度，在相同的时间里处理更多的数据。

列式存储：通过按列存储提高单位时间里数据的I/O吞吐率，还能跳过不需要访问的列。
索引：利用索引配合查询条件，可以迅速跳过不符合条件的数据块，
仅扫描需要扫描的数据内容。

压缩：压缩数据然后存储，使得存储的密度更高，在有限的I/O速率下，在单位时间里读取更多的记录。

 
综上所述，可以注意到，所有这些方法都只是提高了单位时间内处理数据的能力，当大家都一致采用这些技术时，它们之间的区别将只停留在实现层面的代码细节上。最重要的是，这些技术都不会改变一个事实，那就是处理时间与数据量之间的正比例关系。当数据量翻倍时，
MPP（在不扩容的前提下）需要翻倍的时间来完成计算；列式存储需要翻倍的存储空间；索引下符合条件的记录数也会翻倍；压缩后的数据大小也还是之前的两倍。因此查询速度也会随之变成之前的两倍。当数据量成十倍百倍地增长时，这些技术的查询速度就会成十倍百倍地下降，最终变得不能接受。这是因为大规模并行处理和列式存储虽然提高了计算和存储的速度，但并没有改变查询问题本身的时间复杂度，也没有改变查询时间与数据量成线性增长的关系这一事实。假设查询1亿条记录耗时1分钟，那么查询10亿条记录就需10分钟，100亿条记录就至少需要1小时40分钟。当然，可以用很多的优化技术缩短查询的时间，比如更快的存储、更高效的压缩算法，等等，但总体来说，查询性能与数据量呈线性相关这一点是无法改变的。虽然大规模并行处理允许十倍或百倍地扩张计算集群，以
期望保持分钟级别的查询速度，但购买和部署十倍或百倍的计算集群又
怎能轻易做到，更何况还有高昂的硬件运维成本。


Apache Kylin的特色在于，在上述的底层技术之外，另辟蹊径地使用了独特的Cube预计算技术。预计算事先将数据按维度组合进行了聚合，将结果保存为物化视图。Apache Kylin的初衷就是要解决千亿条、万亿条记录的秒级查询问题，其中的关键就是要打破查询时间随着数据量成线性增长的这个规律。仔细思考大数据OLAP，可以注意到两个事实。大数据查询要的一般是统计结果，是多条记录经过聚合函数计算后的统计值。原始的记录则不是必需的，或者访问频率和概率都极低。·聚合是按维度进行的，由于业务范围和分析需求是有限的，有意义的维度聚合组合也是相对有限的，一般不会随着数据的膨胀而增长。基于以上两点，可以得到一个新的思路——“预计算”。应尽量多地预先计算聚合结果，在查询时刻应尽量使用预算的结果得出查询结果，从而避免直接扫描可能无限增长的原始记录。经过聚合，物化视图的规模就只由维度的基数来决定，而不再随着数据量的增长呈线性增长。以电商为例，如果业务扩张，交易量增长了10倍，只要交易数据的维度不变（供应商/商品数量不变），聚合后的物化视图将依旧是原先的大小，查询的速度也将保持不变。
 
 

与那些类似产品相比，这一底层技术的区别使得Kylin从外在功能上呈现出了不同的特性，具体如下。

SQL接口：除了Druid以外，所有的产品都支持SQL或类SQL接口。巧合的是，Druid也是除了Kylin以外，查询性能相对更好的一个。这点除了Druid有自己的存储引擎之外，可能还得益于其较为受限的查询能力。

大数据支持：大多数产品的能力在亿级到十亿级数据量之间，再大的数据量将显著降低查询的性能。而Kylin因为采用预计算技术，因此查询速度不受数据量限制。有实际案例证明数据量在千亿级别时，Kylin系统仍然能够保有秒级别的查询性能。

查询速度：如前文所述，一般产品的查询速度都会不可避免地随着数据量的增长而下降，而Kylin则能够在数据量成倍增长的同时，查询速度保持不变，而且这个差距也将随着数据量的成倍增长而变得愈加明显。

吞吐率：根据之前的实验数据，Kylin的单例吞吐量一般在每秒70个查询左右，并且可以线性扩展，而普通的产品因为所有计算都在查询时完成，所以需要调动集群的更多资源才能完成查询，通常极限在每秒20个查询左右，而且扩容成本较高，需要扩展整个集群。相对的，Kylin系统因为瓶颈不在整个集群，而在于Kylin服务器，因此只需要增加Kylin服务
器就能成倍地提高吞吐率，扩容成本低廉。

与hadoop的关系
	 
从上图可以看到，Apache Kylin与Hadoop是紧耦合的关系，底层是依赖与hadoop。数据来源于hive，利用MapReduce+Yarn构建cube，将预计算结果存储于hbase。无论是全量构建、增量构建还是流式处理，都有计算引擎的可扩展问题。由于kylin自身并不维护数据，因此Kylin的核心部分可以只关注预计算的优化、查询的优化等核心问题，将计算的扩展性委托给其他的计算框架如MapReduce、Spark等，将存储的高可用性问题，扩容问题交给其他的存储框架如HBase等。换而言之，Kylin可以更好地复用用户生产环境中已经广泛部署的其他组件，更好地融入Hadoop、Spark这样的生态圈之中。这样不仅节省了用户在基础设施上的投入，也节约了运维的管理成本，最主要的是使得Kylin产品本身非常灵活，而且容易部署。

增量构建
每次Cube的构建都会从Hive中批量读取数据，而对于大多数业务场景来说，Hive中的数据处于不断增长的状态。为了支持Cube中的数据能够不断地得到更新，且无需重复地为已经处理过的历史数据构建Cube，因此对于Cube引入了增量构建的功能。将Cube划分为多个Segment，每个Segment用起始时间和结束时间来标志。Segment代表一段时间内源数据的预计算结果。在大部分情况下，一个Segment的起始时间等于它之前那个Segment的结束时间，同理，它的结束时间等于它后面那个Segment的起始时间。同一个Cube下不同的Segment除了背后的源数据不同之外，其他如结构定义、构建过程、优化方法、存储方式等都完全相同。
 
全量构建可以看作增量构建的一种特例：在全量构建中，Cube中只存在唯一的一个Segment，该Segment没有分割时间的概念，因此也就没有起始时间和结束时间。全量构建和增量构建各有其适用的场景，用户可以根据自己的业务场景灵活地进行切换。对于全量构建来说，每当需要更新Cube数据的时候，它不会区分历史数据和新加入的数据，也就是说，在构建的时候会导入并处理所有的原始数据。而增量构建只会导入新Segment指定的时间区间内的原始数据，并只对这部分原始数据进行预计算。其次，增量构建的Cube和全量构建的Cube在查询时也有不同。对于增量构建的Cube，由于不同时间的数据分布在不同的Segment之中，因此为了获得完整的数据，查询引擎需要向存储引擎请求读取各个Segment的数据。当然，查询引擎会根据查询中的条件自动跳过不感兴趣的Segment。对于全量构建的Cube，查询引擎只需要向存储引擎访问单个Segment所对应的数据，从存储层返回的数据无需进行Segment之间的聚合。
全量构建和增量构建的详细对比如下表所示。
 


流式构建Cube
Kylin中的增量构建，可用来满足业务的数据更新需求。增量构建和全量构建一样，都需要从Hive中抽取数据，在经过若干轮的MapReduce作业之后，才能对源数据进行预计算，最后将预计算的结果适配成存储引擎所需要的格式，并导入到存储引擎中。一般来说，增量构建的数据量明显小于全量构建，因此增量构建的时间少于全量构建。但是增量构建仍然无法满足分钟级的实时数据更新需求，其中很大一部分原因是实时数据落地到Hive，再由Kylin触发构建任务，并从Hive中拉取数据这个过程就需要花费大量的时间。另外，尽管它的数据量少于全量构建，但是增量构建的子步骤和全量构建的子步骤相同，调度的成本也不可忽
略。因此，为了满足分钟级别的实时数据更新需求，流式构建则是应对实时数据更新需求的解决方案。
由于实时数据更新频繁，因此对于流式构建，不再要求数据必须提前落地到Hive之中，因为那样做开销过大。Kylin假设在流式构建中，数据是以消息流的形式传递给流式构建引擎的。消息流中的每条消息需要包含如下信息：所有的维度信息。所有的度量信息。业务时间戳。
在消息流中，每条消息中的数据结构应该相同，并且可以用同一个分析器实例将每条消息中的维度、度量及时间戳信息提取出来。由于Kafka的性能表现出色，且具有高可用性和可扩展性，因此被广泛地选择为实时消息队列。尽管Kafka之于Kylin是一个类似于Hive的可扩展组件，理论上也存在一些其他消息队列可作为流式构建的数据源，但是因为Kafka的流行程度，它已经成为Kylin事实上的流式构建消息队列标准。

由于消息队列中的键值对是基本固定的，甚至包括衍生时间维度，一经选择也变成是固定的，因此可以创造一个虚拟的表，用表中的各个列来对应消息队列中的维度、度量及衍生时间维度。在查询时，用户可以直接对这张虚拟的表发起各种SQL查询，就好像这张表真实存在一样。
下面的流式构建的例子就是随着时间的推移，同一句sql查出不同的结果。

谈谈kylin与正在使用的Greenplum的对比：
Greenplum:典型的MPP，在众多的大数据的OLAP分析引擎中性能也是相对比较好的，支持的SQL的功能和函数也是非常的多，但是劣势也是非常明显，由于Greenplum的master节点只有一个，而一个查询请求来了以后master做的事情也比较多，既要解析sql生成查询计划，又要把查询计划有序的分发到各个工作节点，还要负责汇总从各个节点传回来的数据，所以master本身就是一个责任很重的组件，还只是个单点的，无法水平扩容来分担压力，所以一个集群里的master以及master与其他节点的网络带宽就很容易成为一个瓶颈，导致整个集群支持的并发数不大，吞吐量很低，印象中在XX项目上的Greenplum集群能同时支持的并发量不到40，如果此时一个很复杂的sql提交到gp，会拖慢整个gp集群，并发量会更低。我们现在目前虽然在XX项目用了gp来应对对实时响应比较高的场景，但是目前的情况看来，在业务使用高峰期还是有很多请求得不到快速的响应。而且gp本身就不是用来应对这种场景的，gp提供了很多高级的功能，包括复杂的函数，灵活的开窗函数，与python等脚本语言的集成，甚至还可以做机器学习，还可以与hdfs集成，最适合的场景是复杂的需求多变的探索式的interactive ad-hoc analyses,而我们现在却把gp用来支撑查询场景非常固定的业务查询，虽然能凑合着用，但随着XX项目业务访问量的增大，gp的并发弱势会越来越影响业务。

Kylin:采用了预计算，kylin适合在超大数据集下统计分析类的查询，数据量越大越能发挥kylin的优势，合理构建cube，90%的sql都能在1秒左右返回。GP的劣势刚好是kylin的优势，比如随着数据量的增大，GP在不扩容的情况下查询消耗的计算资源会越来越多查询时间也越来越长，而kylin预计算后，每次查询都不用扫描原始数据，只需要根据预先定义的cube去查询hbase里预先算好的结果，根据sql查询条件中的filter和group的维度可以快速定位到hbase中的rowkey，只需匹配所需的少量数据就可以，消耗的计算资源是相当轻量级的，不管数据量有多大，只要维度的总数不多以及维度的基数变化不大，查询的效率也是没多大变化的，而且由于查询所消耗的计算资源少，因此能支持的并发量就高了，吞吐量也就大了，而且kylin还可以支持水平扩容，扩容后的吞吐量也是线性增大的。但是kylin也是有弱势的，就是它查询的场景主要是以聚合分析为主，不适合查明细数据（从一些官方测试情况和原理推断可以得出这个结论）。而且查询的场景会收到cube定义的限制，如果cube的定义中本来没有定义a指标和b维度，而查询的sql里出现了a指标或b维度，那么kylin的查询就会失效，所以kylin适合预先知道有哪些查询场景，而且可能出现的查询场景去定义cube。如果事先不知道查询场景，随意定义cube，而如果该表的维度又非常多，那么可能会导致构建出来的cube的膨胀率非常大，占据非常多的存储空间，就是所谓的“维度爆炸”的问题。所以一般使用kylin的场景都是预先知道查询场景，有着固定的模式，根据这些场景去构建cube。Kylin还有一个劣势就是，一旦cube构建成功后，cube是不可变的，如果用于构建这个cube的hive源发生了变化（更新），那么就要重新构建这个cube（refresh操作），而构建cube的代价是很大的（要经过很多步骤且每一步都要花很长时间），一般是一天构建一次，所以kylin也不适合数据频繁变化的场景，比如XX项目每15分钟数据就更新一次，要是使用kylin的话则需频繁刷新cube，要满足15分钟更新cube是几乎不可能的，而kylin的流式构建也只能应对数据实时增加的场景，不能应对数据实时变化的场景。

 


